{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | t_dat       customer_id                                                       article_id\n",
      "   | date32      str32                                                                  int32\n",
      "-- + ----------  ----------------------------------------------------------------  ----------\n",
      " 0 | 2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318   663713001\n",
      " 1 | 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c170ef4305747114d6a67   562245034\n",
      " 2 | 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c170ef4305747114d6a67   615367008\n",
      " 3 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2   508227002\n",
      " 4 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2   573017003\n",
      " 5 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2   384654004\n",
      " 6 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2   633535003\n",
      " 7 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2   615525003\n",
      " 8 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2   508227020\n",
      " 9 | 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c170ef4305747114d6a67   562245006\n",
      "[10 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datatable as dt\n",
    "\n",
    "df_dt_train = dt.fread('data/train.csv', columns = {\"price\":None, \"sales_channel_id\":None})\n",
    "print(df_dt_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Time        customer_id                                                          ItemId\n",
      "   | date32      str32                                                                 int32\n",
      "-- + ----------  ----------------------------------------------------------------  ---------\n",
      " 0 | 2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318  663713001\n",
      " 1 | 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c170ef4305747114d6a67  562245034\n",
      " 2 | 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c170ef4305747114d6a67  615367008\n",
      " 3 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2  508227002\n",
      " 4 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2  573017003\n",
      " 5 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2  384654004\n",
      " 6 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2  633535003\n",
      " 7 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2  615525003\n",
      " 8 | 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d10402a4ecc3594d4b2  508227020\n",
      " 9 | 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c170ef4305747114d6a67  562245006\n",
      "[10 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dt_train.names = {\"t_dat\" : \"Time\", \"article_id\" : \"ItemId\"}\n",
    "print(df_dt_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_session_id(row):\n",
    "    # print(type(row[\"Time\"]))\n",
    "    # print(str(row(\"Time\")))\n",
    "    return f\"{row['customer_id']}:{str(datetime.fromisoformat(str(row['Time'])).isocalendar()[0])}:{str(datetime.fromisoformat(str(row['Time'])).isocalendar()[1])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sessions(df):\n",
    "    df[\"SessionId\"] = df.apply(get_session_id, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_dt_train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time                                        customer_id     ItemId  \\\n",
      "0 2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  663713001   \n",
      "1 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c17...  562245034   \n",
      "2 2018-09-20  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c17...  615367008   \n",
      "3 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d...  508227002   \n",
      "4 2018-09-20  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d...  573017003   \n",
      "\n",
      "                                           SessionId  \n",
      "0  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  \n",
      "1  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c17...  \n",
      "2  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c17...  \n",
      "3  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d...  \n",
      "4  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train_session = create_sessions(df_train)\n",
    "print(df_train_session.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time     ItemId                                          SessionId\n",
      "0 2018-09-20  663713001  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...\n",
      "1 2018-09-20  562245034  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c17...\n",
      "2 2018-09-20  615367008  a8c746a9230ef3a1d535949d6f74c5922a88591b1d4c17...\n",
      "3 2018-09-20  508227002  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d...\n",
      "4 2018-09-20  573017003  a8cf43214284500a1e492dddbc23fe48f8fb42cd313f6d...\n"
     ]
    }
   ],
   "source": [
    "df_train_session = df_train_session.drop([\"customer_id\"], axis = 1)\n",
    "\n",
    "print(df_train_session.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_session.to_csv(\"data/train_session.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import autograd, nn\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "class IndexedAdagradM(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=0.05, momentum=0.0, eps=1e-6):\n",
    "        if lr <= 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if eps <= 0.0:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "\n",
    "        defaults = dict(lr=lr, momentum=momentum, eps=eps)\n",
    "        super(IndexedAdagradM, self).__init__(params, defaults)\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['acc'] = torch.full_like(p, 0, memory_format=torch.preserve_format)\n",
    "                if momentum > 0: state['mom'] = torch.full_like(p, 0, memory_format=torch.preserve_format)\n",
    "\n",
    "    def share_memory(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['acc'].share_memory_()\n",
    "                if group['momentum'] > 0: state['mom'].share_memory_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad\n",
    "                state = self.state[p]\n",
    "                clr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                if grad.is_sparse:\n",
    "                    grad = grad.coalesce()\n",
    "                    grad_indices = grad._indices()[0]\n",
    "                    grad_values = grad._values()\n",
    "                    accs = state['acc'][grad_indices] + grad_values.pow(2)\n",
    "                    state['acc'].index_copy_(0, grad_indices, accs)\n",
    "                    accs.add_(group['eps']).sqrt_().mul_(-1/clr)\n",
    "                    if momentum > 0:\n",
    "                        moma = state['mom'][grad_indices]\n",
    "                        moma.mul_(momentum).add_(grad_values / accs)\n",
    "                        state['mom'].index_copy_(0, grad_indices, moma)\n",
    "                        p.index_add_(0, grad_indices, moma)\n",
    "                    else:\n",
    "                        p.index_add_(0, grad_indices, grad_values / accs)\n",
    "                else:\n",
    "                    state['acc'].add_(grad.pow(2))\n",
    "                    accs = state['acc'].add(group['eps'])\n",
    "                    accs.sqrt_()\n",
    "                    if momentum > 0:\n",
    "                        mom = state['mom']\n",
    "                        mom.mul_(momentum).addcdiv_(grad, accs, value=-clr)\n",
    "                        p.add_(mom)\n",
    "                    else:\n",
    "                        p.addcdiv_(grad, accs, value=-clr)\n",
    "        return loss\n",
    "\n",
    "def init_parameter_matrix(tensor: torch.Tensor, dim0_scale: int = 1, dim1_scale: int = 1):\n",
    "    sigma = math.sqrt(6.0 / float(tensor.size(0) / dim0_scale + tensor.size(1) / dim1_scale))\n",
    "    return nn.init._no_grad_uniform_(tensor, -sigma, sigma)\n",
    "\n",
    "class GRUEmbedding(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(GRUEmbedding, self).__init__()\n",
    "        self.Wx0 = nn.Embedding(dim_in, dim_out * 3, sparse=True)\n",
    "        self.Wrz0 = nn.Parameter(torch.empty((dim_out, dim_out * 2), dtype=torch.float))\n",
    "        self.Wh0 = nn.Parameter(torch.empty((dim_out, dim_out * 1), dtype=torch.float))\n",
    "        self.Bh0 = nn.Parameter(torch.zeros(dim_out * 3, dtype=torch.float))\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        init_parameter_matrix(self.Wx0.weight, dim1_scale = 3)\n",
    "        init_parameter_matrix(self.Wrz0, dim1_scale = 2)\n",
    "        init_parameter_matrix(self.Wh0, dim1_scale = 1)\n",
    "        nn.init.zeros_(self.Bh0)\n",
    "    def forward(self, X, H):\n",
    "        Vx = self.Wx0(X) + self.Bh0\n",
    "        Vrz = torch.mm(H, self.Wrz0)\n",
    "        vx_x, vx_r, vx_z = Vx.chunk(3, 1)\n",
    "        vh_r, vh_z = Vrz.chunk(2, 1)\n",
    "        r = torch.sigmoid(vx_r + vh_r)\n",
    "        z = torch.sigmoid(vx_z + vh_z)\n",
    "        h = torch.tanh(torch.mm(r * H, self.Wh0) + vx_x)\n",
    "        h = (1.0 - z) * H + z * h\n",
    "        return h\n",
    "\n",
    "class GRU4RecModel(nn.Module):\n",
    "    def __init__(self, n_items, layers=[100], dropout_p_embed=0.0, dropout_p_hidden=0.0, embedding=0, constrained_embedding=True):\n",
    "        super(GRU4RecModel, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        self.layers = layers\n",
    "        self.dropout_p_embed = dropout_p_embed\n",
    "        self.dropout_p_hidden = dropout_p_hidden\n",
    "        self.embedding = embedding\n",
    "        self.constrained_embedding = constrained_embedding\n",
    "        self.start = 0\n",
    "        if constrained_embedding:\n",
    "            n_input = layers[-1]\n",
    "        elif embedding:\n",
    "            self.E = nn.Embedding(n_items, embedding, sparse=True)\n",
    "            n_input = embedding\n",
    "        else:\n",
    "            self.GE = GRUEmbedding(n_items, layers[0])\n",
    "            n_input = n_items\n",
    "            self.start = 1\n",
    "        self.DE = nn.Dropout(dropout_p_embed)\n",
    "        self.G = []\n",
    "        self.D = []\n",
    "        for i in range(self.start, len(layers)):\n",
    "            self.G.append(nn.GRUCell(layers[i-1] if i > 0 else n_input, layers[i]))\n",
    "            self.D.append(nn.Dropout(dropout_p_hidden))\n",
    "        self.G = nn.ModuleList(self.G)\n",
    "        self.D = nn.ModuleList(self.D)\n",
    "        self.Wy = nn.Embedding(n_items, layers[-1], sparse=True)\n",
    "        self.By = nn.Embedding(n_items, 1, sparse=True)\n",
    "        self.reset_parameters()\n",
    "    @torch.no_grad()\n",
    "    def reset_parameters(self):\n",
    "        if self.embedding:\n",
    "            init_parameter_matrix(self.E.weight)\n",
    "        elif not self.constrained_embedding:\n",
    "            self.GE.reset_parameters()\n",
    "        for i in range(len(self.G)):\n",
    "            init_parameter_matrix(self.G[i].weight_ih, dim1_scale = 3)\n",
    "            init_parameter_matrix(self.G[i].weight_hh, dim1_scale = 3)\n",
    "            nn.init.zeros_(self.G[i].bias_ih)\n",
    "            nn.init.zeros_(self.G[i].bias_hh)\n",
    "        init_parameter_matrix(self.Wy.weight)\n",
    "        nn.init.zeros_(self.By.weight)\n",
    "    def _init_numpy_weights(self, shape):\n",
    "        sigma = np.sqrt(6.0 / (shape[0] + shape[1]))\n",
    "        m = np.random.rand(*shape).astype('float32') * 2 * sigma - sigma\n",
    "        return m\n",
    "    @torch.no_grad()\n",
    "    def _reset_weights_to_compatibility_mode(self):\n",
    "        np.random.seed(42)\n",
    "        if self.constrained_embedding:\n",
    "            n_input = self.layers[-1]\n",
    "        elif self.embedding:\n",
    "            n_input = self.embedding\n",
    "            self.E.weight.set_(torch.tensor(self._init_numpy_weights((self.n_items, n_input)), device=self.E.weight.device))\n",
    "        else:\n",
    "            n_input = self.n_items\n",
    "            m = []\n",
    "            m.append(self._init_numpy_weights((n_input, self.layers[0])))\n",
    "            m.append(self._init_numpy_weights((n_input, self.layers[0])))\n",
    "            m.append(self._init_numpy_weights((n_input, self.layers[0])))\n",
    "            self.GE.Wx0.weight.set_(torch.tensor(np.hstack(m), device=self.GE.Wx0.weight.device))\n",
    "            m2 = []\n",
    "            m2.append(self._init_numpy_weights((self.layers[0] , self.layers[0])))\n",
    "            m2.append(self._init_numpy_weights((self.layers[0] , self.layers[0])))\n",
    "            self.GE.Wrz0.set_(torch.tensor(np.hstack(m2), device=self.GE.Wrz0.device))\n",
    "            self.GE.Wh0.set_(torch.tensor(self._init_numpy_weights((self.layers[0] , self.layers[0])), device=self.GE.Wh0.device))\n",
    "            self.GE.Bh0.set_(torch.zeros((self.layers[0]*3,), device=self.GE.Bh0.device))\n",
    "        for i in range(self.start, len(self.layers)):\n",
    "            m = []\n",
    "            m.append(self._init_numpy_weights((n_input, self.layers[i])))\n",
    "            m.append(self._init_numpy_weights((n_input, self.layers[i])))\n",
    "            m.append(self._init_numpy_weights((n_input, self.layers[i])))\n",
    "            self.G[i].weight_ih.set_(torch.tensor(np.vstack(m), device=self.G[i].weight_ih.device))\n",
    "            m2 = []\n",
    "            m2.append(self._init_numpy_weights((self.layers[i] , self.layers[i])))\n",
    "            m2.append(self._init_numpy_weights((self.layers[i] , self.layers[i])))\n",
    "            m2.append(self._init_numpy_weights((self.layers[i] , self.layers[i])))\n",
    "            self.G[i].weight_hh.set_(torch.tensor(np.vstack(m2), device=self.G[i].weight_hh.device))\n",
    "            self.G[i].bias_hh.set_(torch.zeros((self.layers[i]*3,), device=self.G[i].bias_hh.device))\n",
    "            self.G[i].bias_ih.set_(torch.zeros((self.layers[i]*3,), device=self.G[i].bias_ih.device))\n",
    "        self.Wy.weight.set_(torch.tensor(self._init_numpy_weights((self.n_items, self.layers[-1])), device=self.Wy.weight.device))\n",
    "        self.By.weight.set_(torch.zeros((self.n_items, 1), device=self.By.weight.device))\n",
    "    def embed_constrained(self, X, Y=None):\n",
    "        if Y is not None:\n",
    "            XY = torch.cat([X, Y])\n",
    "            EXY = self.Wy(XY)\n",
    "            split = X.shape[0]\n",
    "            E = EXY[:split]\n",
    "            O = EXY[split:]\n",
    "            B = self.By(Y)\n",
    "        else:\n",
    "            E = self.Wy(X)\n",
    "            O = self.Wy.weight\n",
    "            B = self.By.weight\n",
    "        return E, O, B\n",
    "    def embed_separate(self, X, Y=None):\n",
    "        E = self.E(X)\n",
    "        if Y is not None:\n",
    "            O = self.Wy(Y)\n",
    "            B = self.By(Y)\n",
    "        else:\n",
    "            O = self.Wy.weight\n",
    "            B = self.By.weight\n",
    "        return E, O, B\n",
    "    def embed_gru(self, X, H, Y=None):\n",
    "        E = self.GE(X, H)\n",
    "        if Y is not None:\n",
    "            O = self.Wy(Y)\n",
    "            B = self.By(Y)\n",
    "        else:\n",
    "            O = self.Wy.weight\n",
    "            B = self.By.weight\n",
    "        return E, O, B\n",
    "    def embed(self, X, H, Y=None):\n",
    "        if self.constrained_embedding:\n",
    "            E, O, B = self.embed_constrained(X, Y)\n",
    "        elif self.embedding > 0:\n",
    "            E, O, B = self.embed_separate(X, Y)\n",
    "        else:\n",
    "            E, O, B = self.embed_gru(X, H[0], Y)\n",
    "        return E, O, B\n",
    "    def hidden_step(self, X, H, training=False):\n",
    "        for i in range(self.start, len(self.layers)):\n",
    "            X = self.G[i](X, Variable(H[i]))\n",
    "            if training:\n",
    "                X = self.D[i](X)\n",
    "            H[i] = X\n",
    "        return X\n",
    "    def score_items(self, X, O, B):\n",
    "        O = torch.mm(X, O.T) + B.T\n",
    "        return O\n",
    "    def forward(self, X, H, Y, training=False):\n",
    "        E, O, B = self.embed(X, H, Y)\n",
    "        if training: \n",
    "            E = self.DE(E)\n",
    "        if not (self.constrained_embedding or self.embedding):\n",
    "            H[0] = E\n",
    "        Xh = self.hidden_step(E, H, training=training)\n",
    "        R = self.score_items(Xh, O, B)\n",
    "        return R\n",
    "\n",
    "class SampleCache:\n",
    "    def __init__(self, n_sample, sample_cache_max_size, distr, device=torch.device('cuda:0')):\n",
    "        self.device = device\n",
    "        self.n_sample = n_sample\n",
    "        self.generate_length = sample_cache_max_size // n_sample if n_sample > 0 else 0\n",
    "        self.distr = distr\n",
    "        self._refresh()\n",
    "        print('Created sample store with {} batches of samples (type=GPU)'.format(self.generate_length))\n",
    "    def _bin_search(self, arr, x):\n",
    "        l = x.shape[0]\n",
    "        a = torch.zeros(l, dtype=torch.int64, device=self.device)\n",
    "        b = torch.zeros(l, dtype=torch.int64, device=self.device) + arr.shape[0]\n",
    "        while torch.any(a != b):\n",
    "            ab = torch.div((a + b), 2,  rounding_mode='trunc')\n",
    "            val = arr[ab]\n",
    "            amask = (val <= x)\n",
    "            a[amask] = ab[amask] + 1\n",
    "            b[~amask] = ab[~amask]\n",
    "        return a\n",
    "    def _refresh(self):\n",
    "        if self.n_sample <= 0: return\n",
    "        x = torch.rand(self.generate_length * self.n_sample, dtype=torch.float32, device=self.device)\n",
    "        self.neg_samples = self._bin_search(self.distr, x).reshape((self.generate_length, self.n_sample))\n",
    "        self.sample_pointer = 0\n",
    "    def get_sample(self):\n",
    "        if self.sample_pointer >= self.generate_length:\n",
    "            self._refresh()\n",
    "        sample = self.neg_samples[self.sample_pointer]\n",
    "        self.sample_pointer += 1\n",
    "        return sample\n",
    "\n",
    "class SessionDataIterator:\n",
    "    def __init__(self, data, batch_size, n_sample=0, sample_alpha=0.75, sample_cache_max_size=10000000, item_key='ItemId', session_key='SessionId', time_key='Time', session_order='time', device=torch.device('cuda:0'), itemidmap=None):\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        if itemidmap is None:\n",
    "            itemids = data[item_key].unique()\n",
    "            self.n_items = len(itemids)\n",
    "            self.itemidmap = pd.Series(data=np.arange(self.n_items, dtype='int32'), index=itemids, name='ItemIdx')\n",
    "        else:\n",
    "            print('Using existing item ID map')\n",
    "            self.itemidmap = itemidmap\n",
    "            self.n_items = len(itemidmap)\n",
    "            in_mask = data[item_key].isin(itemidmap.index.values)\n",
    "            n_not_in = (~in_mask).sum()\n",
    "            if n_not_in > 0:\n",
    "                #print('{} rows of the data contain unknown items and will be filtered'.format(n_not_in))\n",
    "                data = data.drop(data.index[~in_mask])\n",
    "        self.sort_if_needed(data, [session_key, time_key])\n",
    "        self.offset_sessions = self.compute_offset(data, session_key)\n",
    "        if session_order == 'time':\n",
    "            self.session_idx_arr = np.argsort(data.groupby(session_key)[time_key].min().values)\n",
    "        else:\n",
    "            self.session_idx_arr = np.arange(len(self.offset_sessions) - 1)\n",
    "        self.data_items = self.itemidmap[data[item_key].values].values\n",
    "        if n_sample > 0:\n",
    "            pop = data.groupby(item_key).size()\n",
    "            pop = pop[self.itemidmap.index.values].values**sample_alpha\n",
    "            pop = pop.cumsum() / pop.sum()\n",
    "            pop[-1] = 1\n",
    "            distr = torch.tensor(pop, device=self.device, dtype=torch.float32)\n",
    "            self.sample_cache = SampleCache(n_sample, sample_cache_max_size, distr, device=self.device)\n",
    "\n",
    "    def sort_if_needed(self, data, columns, any_order_first_dim=False):\n",
    "        is_sorted = True\n",
    "        neq_masks = []\n",
    "        for i, col in enumerate(columns):\n",
    "            dcol = data[col]\n",
    "            neq_masks.append(dcol.values[1:]!=dcol.values[:-1])\n",
    "            if i == 0:\n",
    "                if any_order_first_dim:\n",
    "                    is_sorted = is_sorted and (dcol.nunique() == neq_masks[0].sum() + 1)\n",
    "                else:\n",
    "                    is_sorted = is_sorted and np.all(dcol.values[1:] >= dcol.values[:-1])\n",
    "            else:\n",
    "                is_sorted = is_sorted and np.all(neq_masks[i - 1] | (dcol.values[1:] >= dcol.values[:-1]))\n",
    "            if not is_sorted:\n",
    "                break\n",
    "        if is_sorted:\n",
    "            print('The dataframe is already sorted by {}'.format(', '.join(columns)))\n",
    "        else:\n",
    "            print('The dataframe is not sorted by {}, sorting now'.format(col))\n",
    "            t0 = time.time()\n",
    "            data.sort_values(columns, inplace=True)\n",
    "            t1 = time.time()\n",
    "            print('Data is sorted in {:.2f}'.format(t1 - t0))\n",
    "\n",
    "    def compute_offset(self, data, column):\n",
    "        offset = np.zeros(data[column].nunique() + 1, dtype=np.int32)\n",
    "        offset[1:] = data.groupby(column).size().cumsum()\n",
    "        return offset\n",
    "\n",
    "    def __call__(self, enable_neg_samples, reset_hook=None):\n",
    "        batch_size = self.batch_size\n",
    "        iters = np.arange(batch_size)\n",
    "        maxiter = iters.max()\n",
    "        start = self.offset_sessions[self.session_idx_arr[iters]]\n",
    "        end = self.offset_sessions[self.session_idx_arr[iters]+1]\n",
    "        finished = False\n",
    "        valid_mask = np.ones(batch_size, dtype='bool')\n",
    "        n_valid = self.batch_size\n",
    "        while not finished:\n",
    "            minlen = (end-start).min()\n",
    "            out_idx = torch.tensor(self.data_items[start], requires_grad=False, device=self.device)\n",
    "            for i in range(minlen-1):\n",
    "                in_idx = out_idx\n",
    "                out_idx = torch.tensor(self.data_items[start+i+1], requires_grad=False, device=self.device)\n",
    "                if enable_neg_samples:\n",
    "                    sample = self.sample_cache.get_sample()\n",
    "                    y = torch.cat([out_idx, sample])\n",
    "                else:\n",
    "                    y = out_idx\n",
    "                yield in_idx, y\n",
    "            start = start+minlen-1\n",
    "            finished_mask = (end-start<=1)\n",
    "            n_finished = finished_mask.sum()\n",
    "            iters[finished_mask] = maxiter + np.arange(1,n_finished+1)\n",
    "            maxiter += n_finished\n",
    "            valid_mask = (iters < len(self.offset_sessions)-1)\n",
    "            n_valid = valid_mask.sum()\n",
    "            if n_valid == 0:\n",
    "                finished = True\n",
    "                break\n",
    "            mask = finished_mask & valid_mask\n",
    "            sessions = self.session_idx_arr[iters[mask]]\n",
    "            start[mask] = self.offset_sessions[sessions]\n",
    "            end[mask] = self.offset_sessions[sessions+1]\n",
    "            iters = iters[valid_mask]\n",
    "            start = start[valid_mask]\n",
    "            end = end[valid_mask]\n",
    "            if reset_hook is not None:\n",
    "                finished = reset_hook(n_valid, finished_mask, valid_mask)\n",
    "\n",
    "class GRU4Rec:\n",
    "    def __init__(self, layers=[100], loss='cross-entropy', batch_size=64, dropout_p_embed=0.0,\n",
    "                 dropout_p_hidden=0.0, learning_rate=0.05, momentum=0.0, sample_alpha=0.5, n_sample=2048, embedding=0,\n",
    "                 constrained_embedding=True, n_epochs=10, bpreg=1.0, elu_param=0.5, logq=0.0, device=torch.device('cuda:0')):\n",
    "        self.device = device\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.set_loss_function(loss)\n",
    "        self.elu_param = elu_param\n",
    "        self.bpreg = bpreg\n",
    "        self.logq = logq\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout_p_embed = dropout_p_embed\n",
    "        self.dropout_p_hidden = dropout_p_hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.sample_alpha = sample_alpha\n",
    "        self.n_sample = n_sample\n",
    "        if embedding == 'layersize':\n",
    "            self.embedding = self.layers[0]\n",
    "        else:\n",
    "            self.embedding = embedding\n",
    "        self.constrained_embedding = constrained_embedding\n",
    "        self.n_epochs = n_epochs\n",
    "    def set_loss_function(self, loss):\n",
    "        if loss == 'cross-entropy': self.loss_function = self.xe_loss_with_softmax\n",
    "        elif loss == 'bpr-max': self.loss_function = self.bpr_max_loss_with_elu\n",
    "        else: raise NotImplementedError\n",
    "    def set_params(self, **kvargs):\n",
    "        maxk_len = np.max([len(str(x)) for x in kvargs.keys()])\n",
    "        maxv_len = np.max([len(str(x)) for x in kvargs.values()])\n",
    "        for k,v in kvargs.items():\n",
    "            if not hasattr(self, k):\n",
    "                print('Unkown attribute: {}'.format(k))\n",
    "                raise NotImplementedError\n",
    "            else:\n",
    "                if type(v) == str and type(getattr(self, k)) == list: v = [int(l) for l in v.split('/')]\n",
    "                if type(v) == str and type(getattr(self, k)) == bool:\n",
    "                    if v == 'True' or v == '1': v = True\n",
    "                    elif v == 'False' or v == '0': v = False\n",
    "                    else:\n",
    "                        print('Invalid value for boolean parameter: {}'.format(v))\n",
    "                        raise NotImplementedError\n",
    "                if k == 'embedding' and v == 'layersize':\n",
    "                    self.embedding = 'layersize'\n",
    "                setattr(self, k, type(getattr(self, k))(v))\n",
    "                if k == 'loss': self.set_loss_function(self.loss)\n",
    "                print('SET   {}{}TO   {}{}(type: {})'.format(k, ' '*(maxk_len-len(k)+3), getattr(self, k), ' '*(maxv_len-len(str(getattr(self, k)))+3), type(getattr(self, k))))\n",
    "        if self.embedding == 'layersize':\n",
    "            self.embedding = self.layers[0]\n",
    "            print('SET   {}{}TO   {}{}(type: {})'.format('embedding', ' '*(maxk_len-len('embedding')+3), getattr(self, 'embedding'), ' '*(maxv_len-len(str(getattr(self, 'embedding')))+3), type(getattr(self, 'embedding'))))\n",
    "    def xe_loss_with_softmax(self, O, Y, M):\n",
    "        if self.logq > 0:\n",
    "            O = O - self.logq * torch.log(torch.cat([self.P0[Y[:M]], self.P0[Y[M:]]**self.sample_alpha]))\n",
    "        X = torch.exp(O - O.max(dim=1, keepdim=True)[0])\n",
    "        X = X / X.sum(dim=1, keepdim=True)\n",
    "        return -torch.sum(torch.log(torch.diag(X)+1e-24))\n",
    "    def softmax_neg(self, X):\n",
    "        hm = 1.0 - torch.eye(*X.shape, out=torch.empty_like(X))\n",
    "        X = X * hm\n",
    "        e_x = torch.exp(X - X.max(dim=1, keepdim=True)[0]) * hm\n",
    "        return e_x / e_x.sum(dim=1, keepdim=True)\n",
    "    def bpr_max_loss_with_elu(self, O, Y, M):\n",
    "        if self.elu_param > 0:\n",
    "            O = nn.functional.elu(O, self.elu_param)\n",
    "        softmax_scores = self.softmax_neg(O)\n",
    "        target_scores = torch.diag(O)\n",
    "        target_scores = target_scores.reshape(target_scores.shape[0],-1)\n",
    "        return torch.sum((-torch.log(torch.sum(torch.sigmoid(target_scores-O)*softmax_scores, dim=1)+1e-24)+self.bpreg*torch.sum((O**2)*softmax_scores, dim=1)))\n",
    "    def fit(self, data, sample_cache_max_size=10000000, compatibility_mode=True, item_key='ItemId', session_key='SessionId', time_key='Time', save_path = \"gru\"):\n",
    "        self.error_during_train = False\n",
    "        self.data_iterator = SessionDataIterator(data, self.batch_size, n_sample=self.n_sample, sample_alpha=self.sample_alpha, sample_cache_max_size=sample_cache_max_size, item_key=item_key, session_key=session_key, time_key=time_key, session_order='time', device=self.device)\n",
    "        if self.logq and self.loss == 'cross-entropy':\n",
    "            pop = data.groupby(item_key).size()\n",
    "            self.P0 = torch.tensor(pop[self.data_iterator.itemidmap.index.values], dtype=torch.float32, device=self.device)\n",
    "        model = GRU4RecModel(self.data_iterator.n_items, self.layers, self.dropout_p_embed, self.dropout_p_hidden, self.embedding, self.constrained_embedding).to(self.device)\n",
    "        if compatibility_mode: \n",
    "            model._reset_weights_to_compatibility_mode()\n",
    "        self.model = model\n",
    "        opt = IndexedAdagradM(self.model.parameters(), self.learning_rate, self.momentum)\n",
    "        for epoch in range(self.n_epochs):\n",
    "            t0 = time.time()\n",
    "            H = []\n",
    "            for i in range(len(self.layers)):\n",
    "                H.append(torch.zeros((self.batch_size, self.layers[i]), dtype=torch.float32, requires_grad=False, device=self.device))\n",
    "            c = []\n",
    "            cc = []\n",
    "            n_valid = self.batch_size\n",
    "            reset_hook = lambda n_valid, finished_mask, valid_mask: self._adjust_hidden(n_valid, finished_mask, valid_mask, H)\n",
    "            for in_idx, out_idx in self.data_iterator(enable_neg_samples=(self.n_sample>0), reset_hook=reset_hook):\n",
    "                for h in H: h.detach_()\n",
    "                self.model.zero_grad()\n",
    "                R = self.model.forward(in_idx, H, out_idx, training=True)\n",
    "                L = self.loss_function(R, out_idx, n_valid) / self.batch_size\n",
    "                L.backward()\n",
    "                opt.step()\n",
    "                L = L.cpu().detach().numpy()\n",
    "                c.append(L)\n",
    "                cc.append(n_valid)\n",
    "                if np.isnan(L):\n",
    "                    print(str(epoch) + ': NaN error!')\n",
    "                    self.error_during_train = True\n",
    "                    return\n",
    "            c = np.array(c)\n",
    "            cc = np.array(cc)\n",
    "            avgc = np.sum(c * cc) / np.sum(cc)\n",
    "            if np.isnan(avgc):\n",
    "                print('Epoch {}: NaN error!'.format(str(epoch)))\n",
    "                self.error_during_train = True\n",
    "                return\n",
    "            t1 = time.time()\n",
    "            dt = t1 - t0\n",
    "            print('Epoch{} --> loss: {:.6f} \\t({:.2f}s) \\t[{:.2f} mb/s | {:.0f} e/s]'.format(epoch+1, avgc, dt, len(c)/dt, np.sum(cc)/dt))\n",
    "            torch.save(self, save_path + \"_epoch_\" + str(epoch) + \".pt\")\n",
    "    def _adjust_hidden(self, n_valid, finished_mask, valid_mask, H):\n",
    "        if (self.n_sample == 0) and (n_valid < 2):\n",
    "            return True\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(self.layers)):\n",
    "                H[i][finished_mask] = 0\n",
    "        if n_valid < len(valid_mask):\n",
    "            for i in range(len(H)):\n",
    "                H[i] = H[i][valid_mask]\n",
    "        return False\n",
    "    def to(self, device):\n",
    "        if type(device) == str:\n",
    "            device = torch.device(device)\n",
    "        if device == self.device:\n",
    "            return\n",
    "        if hasattr(self, 'model'):\n",
    "            self.model = self.model.to(device)\n",
    "            self.model.eval()\n",
    "        self.device = device\n",
    "        if hasattr(self, 'data_iterator'):\n",
    "            self.data_iterator.device = device\n",
    "            if hasattr(self.data_iterator, 'sample_cache'):\n",
    "                self.data_iterator.sample_cache.device = device\n",
    "        pass\n",
    "    def savemodel(self, path):\n",
    "        torch.save(self, path)\n",
    "    @classmethod\n",
    "    def loadmodel(cls, path, device='cuda:0'):\n",
    "        gru = torch.load(path, map_location=device)\n",
    "        gru.device = torch.device(device)\n",
    "        if hasattr(gru, 'data_iterator'):\n",
    "            gru.data_iterator.device = torch.device(device)\n",
    "            if hasattr(gru.data_iterator, 'sample_cache'):\n",
    "                gru.data_iterator.sample_cache.device = torch.device(device)\n",
    "        gru.model.eval()\n",
    "        return gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_dt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe is not sorted by SessionId, sorting now\n",
      "Data is sorted in 39.37\n",
      "Created sample store with 4882 batches of samples (type=GPU)\n",
      "Epoch1 --> loss: 4.702105 \t(1594.22s) \t[220.14 mb/s | 14089 e/s]\n",
      "Epoch2 --> loss: 4.435042 \t(1573.85s) \t[222.99 mb/s | 14271 e/s]\n",
      "Epoch3 --> loss: 4.357382 \t(1576.05s) \t[222.68 mb/s | 14252 e/s]\n",
      "Epoch4 --> loss: 4.317782 \t(1576.35s) \t[222.64 mb/s | 14249 e/s]\n",
      "Epoch5 --> loss: 4.292078 \t(1566.32s) \t[224.06 mb/s | 14340 e/s]\n",
      "Epoch6 --> loss: 4.273507 \t(1545.64s) \t[227.06 mb/s | 14532 e/s]\n",
      "Epoch7 --> loss: 4.259781 \t(976.82s) \t[359.28 mb/s | 22994 e/s]\n",
      "Epoch8 --> loss: 4.248557 \t(977.42s) \t[359.06 mb/s | 22980 e/s]\n",
      "Epoch9 --> loss: 4.239573 \t(977.13s) \t[359.17 mb/s | 22987 e/s]\n",
      "Epoch10 --> loss: 4.231924 \t(976.99s) \t[359.22 mb/s | 22990 e/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "gru = GRU4Rec(n_epochs=epochs)\n",
    "gru.fit(df_train_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def batch_eval(gru, test_data, cutoff=[5], batch_size=512, mode='conservative', item_key='ItemId', session_key='SessionId', time_key='Time'):\n",
    "    if gru.error_during_train: \n",
    "        raise Exception('Attempting to evaluate a model that wasn\\'t trained properly (error_during_train=True)')\n",
    "    recall = dict()\n",
    "    mrr = dict()\n",
    "    for c in cutoff:\n",
    "        recall[c] = 0\n",
    "        mrr[c] = 0\n",
    "    H = []\n",
    "    for i in range(len(gru.layers)):\n",
    "        H.append(torch.zeros((batch_size, gru.layers[i]), requires_grad=False, device=gru.device, dtype=torch.float32))\n",
    "    n = 0\n",
    "    reset_hook = lambda n_valid, finished_mask, valid_mask: gru._adjust_hidden(n_valid, finished_mask, valid_mask, H)\n",
    "    data_iterator = SessionDataIterator(test_data, batch_size, 0, 0, 0, item_key, session_key, time_key, device=gru.device, itemidmap=gru.data_iterator.itemidmap)\n",
    "    for in_idxs, out_idxs in data_iterator(enable_neg_samples=False, reset_hook=reset_hook):\n",
    "        for h in H: h.detach_()\n",
    "        O = gru.model.forward(in_idxs, H, None, training=False)\n",
    "        oscores = O.T\n",
    "        tscores = torch.diag(oscores[out_idxs.long()])\n",
    "        if mode == 'standard': ranks = (oscores > tscores).sum(dim=0) + 1\n",
    "        elif mode == 'conservative': ranks = (oscores >= tscores).sum(dim=0)\n",
    "        elif mode == 'median':  ranks = (oscores > tscores).sum(dim=0) + 0.5*((oscores == tscores).dim(axis=0) - 1) + 1\n",
    "        else: raise NotImplementedError\n",
    "        for c in cutoff:\n",
    "            recall[c] += (ranks <= c).sum().cpu().numpy()\n",
    "            mrr[c] += ((ranks <= c) / ranks.float()).sum().cpu().numpy()\n",
    "        n += O.shape[0]\n",
    "    for c in cutoff:\n",
    "        recall[c] /= n\n",
    "        mrr[c] /= n\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | t_dat       customer_id                                                       article_id\n",
      "   | date32      str32                                                                  int32\n",
      "-- + ----------  ----------------------------------------------------------------  ----------\n",
      " 0 | 2020-09-07  a8b44dd9b88f974b7bc8df197e550038f523ad146696cf3c354f412ecac50fa8   860395002\n",
      " 1 | 2020-09-07  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d58970a617aa3874cfc9   914805002\n",
      " 2 | 2020-09-07  a89ebd644593a3d9921ab489ddfd90b48f8598f3caaf7c368e92892d4dce5ee4   685813003\n",
      " 3 | 2020-09-07  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d58970a617aa3874cfc9   891898001\n",
      " 4 | 2020-09-07  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d58970a617aa3874cfc9   817491006\n",
      " 5 | 2020-09-07  a8aa49d42bc179ee2281ad379d891101d21fce6e73178eb2bb3c7275ccb23216   557599022\n",
      " 6 | 2020-09-07  a8aa49d42bc179ee2281ad379d891101d21fce6e73178eb2bb3c7275ccb23216   828295008\n",
      " 7 | 2020-09-07  a8b6e1717175f8d9f9ade7a5af528de6b97f78afc167e1899277386441b418b7   863595006\n",
      " 8 | 2020-09-07  a8b859735f8f342925f290e0024bcb107f4e9c33ddfa9176f6deab315714d387   598755002\n",
      " 9 | 2020-09-07  a8b44dd9b88f974b7bc8df197e550038f523ad146696cf3c354f412ecac50fa8   910292001\n",
      "[10 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dt_test = dt.fread('data/test.csv', columns = {\"price\":None, \"sales_channel_id\":None})\n",
    "print(df_dt_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Time        customer_id                                                          ItemId\n",
      "   | date32      str32                                                                 int32\n",
      "-- + ----------  ----------------------------------------------------------------  ---------\n",
      " 0 | 2020-09-07  a8b44dd9b88f974b7bc8df197e550038f523ad146696cf3c354f412ecac50fa8  860395002\n",
      " 1 | 2020-09-07  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d58970a617aa3874cfc9  914805002\n",
      " 2 | 2020-09-07  a89ebd644593a3d9921ab489ddfd90b48f8598f3caaf7c368e92892d4dce5ee4  685813003\n",
      " 3 | 2020-09-07  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d58970a617aa3874cfc9  891898001\n",
      " 4 | 2020-09-07  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d58970a617aa3874cfc9  817491006\n",
      " 5 | 2020-09-07  a8aa49d42bc179ee2281ad379d891101d21fce6e73178eb2bb3c7275ccb23216  557599022\n",
      " 6 | 2020-09-07  a8aa49d42bc179ee2281ad379d891101d21fce6e73178eb2bb3c7275ccb23216  828295008\n",
      " 7 | 2020-09-07  a8b6e1717175f8d9f9ade7a5af528de6b97f78afc167e1899277386441b418b7  863595006\n",
      " 8 | 2020-09-07  a8b859735f8f342925f290e0024bcb107f4e9c33ddfa9176f6deab315714d387  598755002\n",
      " 9 | 2020-09-07  a8b44dd9b88f974b7bc8df197e550038f523ad146696cf3c354f412ecac50fa8  910292001\n",
      "[10 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dt_test.names = {\"t_dat\" : \"Time\", \"article_id\" : \"ItemId\"}\n",
    "print(df_dt_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_dt_test.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time     ItemId                                          SessionId\n",
      "0 2020-09-07  860395002  a8b44dd9b88f974b7bc8df197e550038f523ad146696cf...\n",
      "1 2020-09-07  914805002  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d5...\n",
      "2 2020-09-07  685813003  a89ebd644593a3d9921ab489ddfd90b48f8598f3caaf7c...\n",
      "3 2020-09-07  891898001  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d5...\n",
      "4 2020-09-07  817491006  a8a2bc1895534eb61e197e56919483d6ae5337a4dff0d5...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_test_session = create_sessions(df_test)\n",
    "df_test_session = df_test_session.drop([\"customer_id\"], axis = 1)\n",
    "print(df_test_session.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_session.to_csv(\"data/test_session.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing item ID map\n",
      "The dataframe is not sorted by SessionId, sorting now\n",
      "Data is sorted in 0.26\n",
      "({1: 0.11309564778489, 3: 0.16340881455479844, 5: 0.18575110315766932, 10: 0.21788606694656665, 20: 0.2531718172849703, 50: 0.309966274347856}, {1: 0.11309564778489, 3: 0.1353340603455584, 5: 0.1404248350588883, 10: 0.14469873662908816, 20: 0.1471320124855033, 50: 0.1489270858494844})\n"
     ]
    }
   ],
   "source": [
    "cutoffs = [1, 3, 5, 10, 20, 50]\n",
    "res = batch_eval(gru,df_test_session,cutoff=cutoffs)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
